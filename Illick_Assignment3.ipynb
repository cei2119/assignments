{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e6be8a9-254b-4bad-8dda-60cc2066c376",
   "metadata": {},
   "source": [
    "# Part 1 Working with JSON Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5213f4e6-778c-4afc-a7f2-06ff699c5448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may need to install these\n",
    "# pip install pooch requests\n",
    "\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b799527b-da12-497c-9461-2901f4426d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Station: USC00305800\n",
      "Location: {'latitude': 40.7789, 'longitude': -73.9692}\n",
      "First observation: {'date': '2023-01-01', 'temperature': 32, 'precipitation': 0.0}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "# Here's a sample JSON structure similar to what APIs return\n",
    "sample_json = '''\n",
    "{\n",
    "  \"station\": \"USC00305800\",\n",
    "  \"name\": \"New York Central Park\",\n",
    "  \"location\": {\n",
    "    \"latitude\": 40.7789,\n",
    "    \"longitude\": -73.9692\n",
    "  },\n",
    "  \"observations\": [\n",
    "    {\"date\": \"2023-01-01\", \"temperature\": 32, \"precipitation\": 0.0},\n",
    "    {\"date\": \"2023-01-02\", \"temperature\": 28, \"precipitation\": 0.5},\n",
    "    {\"date\": \"2023-01-03\", \"temperature\": 35, \"precipitation\": 0.0},\n",
    "    {\"date\": \"2023-01-04\", \"temperature\": 38, \"precipitation\": 0.2},\n",
    "    {\"date\": \"2023-01-05\", \"temperature\": 41, \"precipitation\": 0.0}\n",
    "  ]\n",
    "}\n",
    "'''\n",
    "\n",
    "# Parse the JSON\n",
    "data = json.loads(sample_json)\n",
    "\n",
    "# Access nested data\n",
    "print(\"Station:\", data['station'])\n",
    "print(\"Location:\", data['location'])\n",
    "print(\"First observation:\", data['observations'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2db09e40-6f5c-4a9f-a5b3-ba534430b92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date, Temperature\n",
      "2023-01-01 32\n",
      "2023-01-02 28\n",
      "2023-01-03 35\n",
      "2023-01-04 38\n",
      "2023-01-05 41\n"
     ]
    }
   ],
   "source": [
    "# 1. Extract and print all dates and temperatures (8 points)\n",
    "print(\"Date, Temperature\")\n",
    "for obs in data['observations']:\n",
    "    # YOUR CODE HERE: print date and temperature for each observation\n",
    "    print(obs['date'], obs['temperature'])\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64f84ca3-6408-4372-943d-9f9825638a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average temperature: 34.8°F\n"
     ]
    }
   ],
   "source": [
    "# 2. Calculate average temperature (8 points)\n",
    "total_temp = 0\n",
    "count = 0\n",
    "# YOUR CODE HERE: calculate average\n",
    "for obs in data['observations']:\n",
    "    total_temp = total_temp + obs['temperature']\n",
    "    count = count + 1\n",
    "avg_temp = total_temp/count  # Replace this\n",
    "print(f\"Average temperature: {avg_temp}°F\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5216f0bc-9a92-45f2-bf96-6e5c8c58b545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Days with precipitation:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Find days with precipitation (9 points)\n",
    "print(\"\\nDays with precipitation:\")\n",
    "# YOUR CODE HERE\n",
    "dayswP = 0\n",
    "for obs in data['observations']:\n",
    "    if obs['precipitation'] > 0:\n",
    "        dayswP += 1\n",
    "dayswP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31695fc4-54cc-4889-8c7b-6734092aba4b",
   "metadata": {},
   "source": [
    "# Part 2: Downloading Files with Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e453f50-231f-497a-8470-a2f44f843915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded to: /home/cei2119/.cache/pooch/458dad453f6a48e510cd544bef1854e3-air_quality_no2.csv\n",
      "File exists: True\n"
     ]
    }
   ],
   "source": [
    "import pooch\n",
    "import os\n",
    "\n",
    "# Set up Pooch to download a file\n",
    "# This example downloads a small air quality dataset\n",
    "file_path = pooch.retrieve(\n",
    "    url=\"https://github.com/pandas-dev/pandas/raw/main/doc/data/air_quality_no2.csv\",\n",
    "    known_hash=None\n",
    ")\n",
    "\n",
    "print(\"File downloaded to:\", file_path)\n",
    "print(\"File exists:\", os.path.exists(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "83c5bc77-f81f-4e64-9d99-1e4e0155e7b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File size: 31984 bytes\n",
      "Number of lines: 1035\n"
     ]
    }
   ],
   "source": [
    "# 1. Verify the file was downloaded (5 points)\n",
    "# Check the file size\n",
    "file_size = os.path.getsize(file_path)\n",
    "print(f\"File size: {file_size} bytes\")\n",
    "\n",
    "# YOUR CODE HERE: open the file and count how many lines it has\n",
    "import pandas as pd\n",
    "line_count = 0\n",
    "df = pd.read_csv(\"/home/cei2119/.cache/pooch/458dad453f6a48e510cd544bef1854e3-air_quality_no2.csv\")\n",
    "for i in df.index: \n",
    "    line_count += 1\n",
    "\n",
    "\n",
    "print(f\"Number of lines: {line_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2b414405-d18d-45d0-a425-f30996c35963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/cei2119/.cache/pooch/c89ae2342e61af4b3a058302cfbc3311-GRACE_GRACE-FO_Months_RL06.csv\n",
      "     Month Sr No  GRACE/GRACE-FO record index MONTH  YEAR  START DAY  YEAR.1  \\\n",
      "0              1                          1.0   APR  2002         91    2002   \n",
      "1              2                          2.0   MAY  2002        121    2002   \n",
      "2              3                          NaN   JUN  2002        152    2002   \n",
      "3              4                          NaN   JUL  2002        182    2002   \n",
      "4              5                          3.0   AUG  2002        213    2002   \n",
      "..           ...                          ...   ...   ...        ...     ...   \n",
      "279          280                        247.0   JUL  2025        182    2025   \n",
      "280          281                        248.0   AUG  2025        213    2025   \n",
      "281          282                        249.0   SEP  2025        244    2025   \n",
      "282          283                        250.0   OCT  2025        274    2025   \n",
      "283          284                        251.0   NOV  2025        305    2025   \n",
      "\n",
      "     END DAY     COMMON MISSING DAYS CSR unused days GFZ unused days  \\\n",
      "0        120      91-93, 100,101,118              94         94, 117   \n",
      "1        151  121, 128, 134, 139-151   122, 127, 138        127, 138   \n",
      "2        181                 152-181             NaN             NaN   \n",
      "3        212                 182-212             NaN             NaN   \n",
      "4        243                     NaN             240             NaN   \n",
      "..       ...                     ...             ...             ...   \n",
      "279      212                     NaN             NaN             NaN   \n",
      "280      243                     NaN             NaN             NaN   \n",
      "281      273                     NaN             NaN             NaN   \n",
      "282      304                     NaN             NaN             NaN   \n",
      "283      334                     NaN             NaN             NaN   \n",
      "\n",
      "    JPL unused days  \n",
      "0               NaN  \n",
      "1               NaN  \n",
      "2               NaN  \n",
      "3               NaN  \n",
      "4               240  \n",
      "..              ...  \n",
      "279             NaN  \n",
      "280             NaN  \n",
      "281             NaN  \n",
      "282             NaN  \n",
      "283             NaN  \n",
      "\n",
      "[284 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "# 2. Download another file (10 points)\n",
    "# Find a climate dataset online using the sources we talked about in lecture\n",
    "# Download it using Pooch\n",
    "\n",
    "# YOUR CODE HERE:\n",
    "my_url = \"https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-docs/gracefo/open/docs/GRACE_GRACE-FO_Months_RL06.csv\"\n",
    "my_file = pooch.retrieve(url=my_url, known_hash=None)  # hash optional for first try\n",
    "#Print info about your downloaded file\n",
    "df2 = pd.read_csv(my_url)\n",
    "print(my_file)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9b2eb5c3-3a1d-4bee-819a-010c5f4bdf4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Inventory:\n",
      "1. meteorites.csv - NASA meteorite landings\n",
      "2. air_quality_no2.csv - Air quality NO2 measurements\n",
      "3. GRACE_GRACE-FO_Months_RL06.csv - GRACE monthly data integration range\n"
     ]
    }
   ],
   "source": [
    "# 3. Create a data inventory (5 points)\n",
    "# List all the files you've downloaded in this assignment\n",
    "print(\"\\nData Inventory:\")\n",
    "print(\"1. meteorites.csv - NASA meteorite landings\")\n",
    "print(\"2. air_quality_no2.csv - Air quality NO2 measurements\")\n",
    "# YOUR CODE HERE: add your file from task 2\n",
    "print(\"3. GRACE_GRACE-FO_Months_RL06.csv - GRACE monthly data integration range\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832a1e05-fafd-428e-8331-38b48540c18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 1. Verify the file was downloaded (5 points)\n",
    "# Check the file size\n",
    "file_size = os.path.getsize(file_path)\n",
    "print(f\"File size: {file_size} bytes\")\n",
    "\n",
    "# YOUR CODE HERE: open the file and count how many lines it has\n",
    "import pandas as pd\n",
    "line_count = 0\n",
    "df = pd.read_csv(\"/home/cei2119/.cache/pooch/c89ae2342e61af4b3a058302cfbc3311-GRACE_GRACE-FO_Months_RL06.csv\")\n",
    "for i in df.index: \n",
    "    line_count += 1\n",
    "    \n",
    "print(f\"Number of lines: {line_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3d9a92-d40f-42d0-9f34-fead2ac968ed",
   "metadata": {},
   "source": [
    "# Part 3: Understanding NetCDF Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6ca378eb-ec92-4022-9d76-49bb57d0a804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Structure:\n",
      "Dataset {\n",
      "    Float32 T[T = 324];\n",
      "    Float32 Y[Y = 360];\n",
      "    Float32 X[X = 720];\n",
      "    Grid {\n",
      "     ARRAY:\n",
      "        Float32 rain[T = 324][Y = 360][X = 720];\n",
      "     MAPS:\n",
      "        Float32 T[T = 324];\n",
      "        Float32 Y[Y = 360];\n",
      "        Float32 X[X = 720];\n",
      "    } rain;\n",
      "} rain;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# OPeNDAP provides metadata in different formats\n",
    "# We'll get basic info about a climate dataset\n",
    "\n",
    "base_url = \"http://iridl.ldeo.columbia.edu/expert/SOURCES/.NOAA/.NCEP/.CPC/.UNIFIED_PRCP/.GAUGE_BASED/.GLOBAL/.v1p0/.Monthly/.RETRO/.rain/dods\"\n",
    "\n",
    "# Get DDS (Dataset Descriptor Structure) - describes the structure\n",
    "dds_url = base_url + \".dds\"\n",
    "response = requests.get(dds_url)\n",
    "\n",
    "print(\"Dataset Structure:\")\n",
    "print(response.text[:500])  # Print first 500 characters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14df9a91-3c10-468c-a236-70ba51a78f7a",
   "metadata": {},
   "source": [
    "# 1. Identify dimensions and variables (5 points)\n",
    "# Look at the DDS output above and answer:\n",
    "# - What are the dimension names?\n",
    "* T\n",
    "* Y\n",
    "* X\n",
    "# - What is the main variable name?\n",
    "* rain\n",
    "# - Write your answers in a markdown cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bd115160-5894-4e05-baec-ce0cf80a1cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Structure:\n",
      "Attributes {\n",
      "    X {\n",
      "        String standard_name \"longitude\";\n",
      "        Float32 pointwidth 0.5;\n",
      "        Int32 gridtype 1;\n",
      "        String units \"degree_east\";\n",
      "    }\n",
      "    T {\n",
      "        Float32 pointwidth 1.0;\n",
      "        String calendar \"360\";\n",
      "        Int32 gridtype 0;\n",
      "        String units \"months since 1960-01-01\";\n",
      "    }\n",
      "    Y {\n",
      "        String standard_name \"latitude\";\n",
      "        Float32 pointwidth 0.5;\n",
      "        Int32 gridtype 0;\n",
      "        String units \"degree_north\";\n",
      "    }\n",
      "    rain {\n",
      "        Int32 pointwidth 0;\n",
      "        String standard_name \"lwe_precipitation_rate\";\n",
      "        Float32 file_missing_value -999.0;\n",
      "        String history \"Boxes with less than 0.0% dropped\";\n",
      "        Float32 missing_value NaN;\n",
      "        String units \"mm/day\";\n",
      "        String long_name \"Monthly Precipitation\";\n",
      "    }\n",
      "NC_GLOBAL {\n",
      "    String Conventions \"IRIDL\";\n",
      "}\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. Get data attributes (5 points)\n",
    "# DAS (Dataset Attribute Structure) contains metadata\n",
    "das_url = base_url + \".das\"\n",
    "# YOUR CODE HERE: make a request to das_url and print first 1000 characters\n",
    "response = requests.get(das_url)\n",
    "\n",
    "print(\"Dataset Structure:\")\n",
    "print(response.text[:1000])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08578886-22e1-4a58-8524-e8f72c49bee8",
   "metadata": {},
   "source": [
    "# 3. Document what you learned (5 points)\n",
    "# In a markdown cell, write:\n",
    "## - What does this dataset contain?\n",
    "* monthly precipitation data, gridded cells based on long lat and time that store rainfall data\n",
    "## - What time period does it cover?\n",
    "* months since 1960-01-01, 324 months since then, 27 years\n",
    "## - What geographic region does it cover?\n",
    "* global dataset with 0.5 degree cells\n",
    "## - What are the units of the main variable?\n",
    "* mm/day\n",
    "# Find this info in the DAS output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pangeo23",
   "language": "python",
   "name": "pangeo23"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
